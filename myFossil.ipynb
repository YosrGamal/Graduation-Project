{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M5Ju4fFQQdDP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from imutils import paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjFYyiwTJTt"
      },
      "source": [
        "# **Moment invariant**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCK2tsTowP4n"
      },
      "source": [
        "Reading image file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = cv2.imread(\"Segmented_Teeth/segmented tooth1_1.png\")\n",
        "img2 = cv2.imread(\"Segmented_Teeth/segmented tooth1_2.png\")\n",
        "img3 = cv2.imread(\"Segmented_Teeth/segmented_tooth1_3.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL MOMENTS for img 1: [9.31673872e-04 3.94367501e-07 1.16589393e-10 1.50416801e-11\n",
            " 6.29560476e-22 9.44115823e-15 2.07860839e-23]\n",
            "ORIGINAL MOMENTS for img 2: [9.32487012e-04 4.19574583e-07 7.85269033e-11 1.14095140e-11\n",
            " 3.37913841e-22 7.05015323e-15 4.94653700e-23]\n",
            "ORIGINAL MOMENTS for img 3: [1.18052474e-03 9.45728897e-07 1.96083982e-10 8.24694512e-11\n",
            " 1.04041240e-20 7.77455385e-14 1.31763320e-21]\n"
          ]
        }
      ],
      "source": [
        "moments1 = cv2.HuMoments(cv2.moments(img1)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 1: {}\".format(moments1))\n",
        "\n",
        "moments2 = cv2.HuMoments(cv2.moments(img2)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 2: {}\".format(moments2))\n",
        "\n",
        "moments3 = cv2.HuMoments(cv2.moments(img3)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 3: {}\".format(moments3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log transformation for moments1 [ 3.03073608  6.40409888  9.93334096 10.82270365 21.20096254 14.02497472\n",
            " 22.68222732]\n",
            "log transformation for moments2 [ 3.03035721  6.37719083 10.10498153 10.94273285 21.47119402 14.15180144\n",
            " 22.30569874]\n",
            "log transformation for moments3 [ 2.92792491  6.02423334  9.70755788 10.0837069  19.98279448 13.10932452\n",
            " 20.88020547]\n"
          ]
        }
      ],
      "source": [
        "# for i in range(0,7):\n",
        "#    moments1[i] = -np.sign(1.0, moments1[i])*np.math.log10(np.abs(moments1[i]))\n",
        "   \n",
        "#-1* copysign(1.0, huMoments[i]) * log10(abs(huMoments[i]))\n",
        "\n",
        "lmoment1 = np.abs(np.log10(moments1))\n",
        "print('log transformation for moments1',lmoment1)\n",
        "lmoment2 = np.abs(np.log10(moments2))\n",
        "print('log transformation for moments2', lmoment2)\n",
        "lmoment3 = np.abs(np.log10(moments3))\n",
        "print('log transformation for moments3', lmoment3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between moment1 and moment2 0.5248576217835638\n"
          ]
        }
      ],
      "source": [
        "dist = np.linalg.norm(lmoment1 - lmoment2)\n",
        "print('Distance between moment1 and moment2',dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between moment1 and moment3 2.5142779577407346\n"
          ]
        }
      ],
      "source": [
        "dist = np.linalg.norm(lmoment1 - lmoment3)\n",
        "print('Distance between moment1 and moment3',dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *Data Augmentation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import argparse\n",
        "from imutils import paths\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "datapath=\"training dataset/crocodiles\"\n",
        "out=\"training dataset/crocodiles_aug\"\n",
        "\n",
        "datapath1=\"training dataset/sharks\"\n",
        "out1=\"training dataset/sharks_aug\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(datapath))\n",
        "imagePaths1 = list(paths.list_images(datapath1))\n",
        "data=[]\n",
        "data1=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "for imagePath in imagePaths:\n",
        "    print(imagePath)\n",
        "    image = cv2.imread(imagePath)\n",
        "\t#cv2.imshow(image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    data.append(image)\n",
        "datanp=np.array(data)\n",
        "\n",
        "for imagePath1 in imagePaths1:\n",
        "    print(imagePath1)\n",
        "    image1 = cv2.imread(imagePath1)\n",
        "\t#cv2.imshow(image)\n",
        "    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "    image1 = cv2.resize(image1, (224, 224))\n",
        "    image1 = img_to_array(image1)\n",
        "    image1 = np.expand_dims(image1, axis=0)\n",
        "    data1.append(image1)\n",
        "datanp1=np.array(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "aug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "total = 0\n",
        "imageGen=[]\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "total = 0\n",
        "imageGen1=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] generating images...\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] generating images...\")\n",
        "\n",
        "# augmentedImages=[]\n",
        "for i in range(len(datanp)):\n",
        "        print(\"Generating is running\")\n",
        "  \n",
        "        imageGen= aug.flow(datanp[i], batch_size=1, save_to_dir=out,\n",
        "        save_prefix=\"image\", save_format=\"jpg\")\n",
        "        for image in imageGen:\n",
        "\t# increment our counter\n",
        "\t        total += 1\n",
        "\t# if we have reached the specified number of examples, break\n",
        "\t# from the loop\n",
        "\t        if (total%6==0):\n",
        "\t\t\t\t#total = 0\n",
        "\t\t        break\n",
        "\n",
        "# augmentedImages=[]\n",
        "for i in range(len(datanp1)):\n",
        "        print(\"Generating is running\")\n",
        "  \n",
        "        imageGen1= aug.flow(datanp1[i], batch_size=1, save_to_dir=out1,\n",
        "        save_prefix=\"image\", save_format=\"jpg\")\n",
        "        for image1 in imageGen1:\n",
        "\t# increment our counter\n",
        "\t        total += 1\n",
        "\t# if we have reached the specified number of examples, break\n",
        "\t# from the loop\n",
        "\t        if (total%6==0):\n",
        "\t\t\t\t#total = 0\n",
        "\t\t        break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **SVM classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir_path = r'/content/drive/Shareddrives/Graduation Project/Dataset/Teeth images'\n",
        "categories = ['Afradapis', 'Elephant', 'Hyrax' , 'Masrasector' , 'Sharks']\n",
        "IMG_SIZE=100\n",
        "for category in categories:\n",
        "  path = os.path.join(dir_path,category)\n",
        "  for img in os.listdir(path):\n",
        "      img_array=cv2.imread(os.path.join(path,img))\n",
        "      plt.imshow(img_array)\n",
        "      plt.show()\n",
        "      break\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_data=[]\n",
        "def create_training_data():\n",
        "    for category in categories:\n",
        "        path=os.path.join(dir_path, category)\n",
        "        class_num=categories.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array=cv2.imread(os.path.join(path,img))\n",
        "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
        "                training_data.append([new_array,class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "create_training_data()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lenofimage = len(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for categories, label in training_data:\n",
        "    X.append(categories)\n",
        "    y.append(label)\n",
        "X= np.array(X).reshape(lenofimage,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X/255.0\n",
        "X[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y=np.array(y)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "svc = svm.SVC(kernel='rbf', C=1,gamma='auto').fit(X, y) #rbf model kernal not linear \n",
        "svc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *CNN classification*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (180,180,3)) ,\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
        "    tf.keras.layers.Dropout(0.1,seed = 2019),\n",
        "    tf.keras.layers.Dense(400,activation =\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.3,seed = 2019),\n",
        "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.4,seed = 2019),\n",
        "    tf.keras.layers.Dense(200,activation =\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2,seed = 2019),\n",
        "    tf.keras.layers.Dense(2,activation = \"softmax\")   #Adding the Output Layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
        "adam=Adam(learning_rate=0.001)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 347 images belonging to 2 classes.\n",
            "Found 14 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "bs=30         #Setting batch size\n",
        "train_dir = \"training dataset\"   #Setting training directory\n",
        "validation_dir = \"validation dataset\"   #Setting testing directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "# All images will be rescaled by 1./255.\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(180,180))\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=bs,\n",
        "                                                         class_mode  = 'categorical',\n",
        "                                                         target_size=(180,180))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12/12 - 8s - loss: 0.6903 - acc: 0.5562 - val_loss: 0.7398 - val_acc: 0.5000 - 8s/epoch - 707ms/step\n",
            "Epoch 2/10\n",
            "12/12 - 7s - loss: 0.6173 - acc: 0.6427 - val_loss: 0.6470 - val_acc: 0.5000 - 7s/epoch - 570ms/step\n",
            "Epoch 3/10\n",
            "12/12 - 7s - loss: 0.5778 - acc: 0.6455 - val_loss: 0.6955 - val_acc: 0.5000 - 7s/epoch - 572ms/step\n",
            "Epoch 4/10\n",
            "12/12 - 8s - loss: 0.6035 - acc: 0.6138 - val_loss: 0.6859 - val_acc: 0.5000 - 8s/epoch - 633ms/step\n",
            "Epoch 5/10\n",
            "12/12 - 7s - loss: 0.5858 - acc: 0.6282 - val_loss: 0.6505 - val_acc: 0.5000 - 7s/epoch - 601ms/step\n",
            "Epoch 6/10\n",
            "12/12 - 7s - loss: 0.5530 - acc: 0.6427 - val_loss: 0.6138 - val_acc: 0.5000 - 7s/epoch - 599ms/step\n",
            "Epoch 7/10\n",
            "12/12 - 8s - loss: 0.5027 - acc: 0.6916 - val_loss: 0.5115 - val_acc: 0.7857 - 8s/epoch - 632ms/step\n",
            "Epoch 8/10\n",
            "12/12 - 7s - loss: 0.4818 - acc: 0.8213 - val_loss: 0.3063 - val_acc: 0.7857 - 7s/epoch - 584ms/step\n",
            "Epoch 9/10\n",
            "12/12 - 7s - loss: 0.4094 - acc: 0.7954 - val_loss: 0.4432 - val_acc: 0.7143 - 7s/epoch - 586ms/step\n",
            "Epoch 10/10\n",
            "12/12 - 8s - loss: 0.3272 - acc: 0.8357 - val_loss: 0.3896 - val_acc: 0.7857 - 8s/epoch - 657ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    # steps_per_epoch=150 // bs,\n",
        "                    epochs=10,\n",
        "                    # validation_steps=50 // bs,\n",
        "                    verbose=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "66eba28a75a64fbe1a9b9c30d27f7c856726c51cbbef86297708eae4ce175db0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
