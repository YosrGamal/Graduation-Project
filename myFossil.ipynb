{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M5Ju4fFQQdDP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjFYyiwTJTt"
      },
      "source": [
        "# **Moment invariant**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCK2tsTowP4n"
      },
      "source": [
        "Reading image file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = cv2.imread(\"Segmented_Teeth/segmented tooth1_1.png\")\n",
        "img2 = cv2.imread(\"Segmented_Teeth/segmented tooth1_2.png\")\n",
        "img3 = cv2.imread(\"Segmented_Teeth/segmented_tooth1_3.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL MOMENTS for img 1: [9.31673872e-04 3.94367501e-07 1.16589393e-10 1.50416801e-11\n",
            " 6.29560476e-22 9.44115823e-15 2.07860839e-23]\n",
            "ORIGINAL MOMENTS for img 2: [9.32487012e-04 4.19574583e-07 7.85269033e-11 1.14095140e-11\n",
            " 3.37913841e-22 7.05015323e-15 4.94653700e-23]\n",
            "ORIGINAL MOMENTS for img 3: [1.18052474e-03 9.45728897e-07 1.96083982e-10 8.24694512e-11\n",
            " 1.04041240e-20 7.77455385e-14 1.31763320e-21]\n"
          ]
        }
      ],
      "source": [
        "moments1 = cv2.HuMoments(cv2.moments(img1)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 1: {}\".format(moments1))\n",
        "\n",
        "moments2 = cv2.HuMoments(cv2.moments(img2)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 2: {}\".format(moments2))\n",
        "\n",
        "moments3 = cv2.HuMoments(cv2.moments(img3)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 3: {}\".format(moments3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log transformation for moments1 [ 3.03073608  6.40409888  9.93334096 10.82270365 21.20096254 14.02497472\n",
            " 22.68222732]\n",
            "log transformation for moments2 [ 3.03035721  6.37719083 10.10498153 10.94273285 21.47119402 14.15180144\n",
            " 22.30569874]\n",
            "log transformation for moments3 [ 2.92792491  6.02423334  9.70755788 10.0837069  19.98279448 13.10932452\n",
            " 20.88020547]\n"
          ]
        }
      ],
      "source": [
        "# for i in range(0,7):\n",
        "#    moments1[i] = -np.sign(1.0, moments1[i])*np.math.log10(np.abs(moments1[i]))\n",
        "   \n",
        "#-1* copysign(1.0, huMoments[i]) * log10(abs(huMoments[i]))\n",
        "\n",
        "lmoment1 = np.abs(np.log10(moments1))\n",
        "print('log transformation for moments1',lmoment1)\n",
        "lmoment2 = np.abs(np.log10(moments2))\n",
        "print('log transformation for moments2', lmoment2)\n",
        "lmoment3 = np.abs(np.log10(moments3))\n",
        "print('log transformation for moments3', lmoment3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between moment1 and moment2 0.5248576217835638\n"
          ]
        }
      ],
      "source": [
        "dist = np.linalg.norm(lmoment1 - lmoment2)\n",
        "print('Distance between moment1 and moment2',dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between moment1 and moment3 2.5142779577407346\n"
          ]
        }
      ],
      "source": [
        "dist = np.linalg.norm(lmoment1 - lmoment3)\n",
        "print('Distance between moment1 and moment3',dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *CNN classification*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (180,180,3)) ,\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
        "    tf.keras.layers.Dropout(0.1,seed = 2019),\n",
        "    tf.keras.layers.Dense(400,activation =\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.3,seed = 2019),\n",
        "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.4,seed = 2019),\n",
        "    tf.keras.layers.Dense(200,activation =\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2,seed = 2019),\n",
        "    tf.keras.layers.Dense(2,activation = \"softmax\")   #Adding the Output Layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
        "adam=Adam(learning_rate=0.001)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 26 images belonging to 2 classes.\n",
            "Found 14 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "bs=30         #Setting batch size\n",
        "train_dir = \"training dataset\"   #Setting training directory\n",
        "validation_dir = \"validation dataset\"   #Setting testing directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "# All images will be rescaled by 1./255.\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(180,180))\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=bs,\n",
        "                                                         class_mode  = 'categorical',\n",
        "                                                         target_size=(180,180))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 - 1s - loss: 0.1311 - acc: 0.9231 - val_loss: 0.3037 - val_acc: 0.8571 - 1s/epoch - 1s/step\n",
            "Epoch 2/10\n",
            "1/1 - 2s - loss: 0.1024 - acc: 0.9615 - val_loss: 0.1910 - val_acc: 0.9286 - 2s/epoch - 2s/step\n",
            "Epoch 3/10\n",
            "1/1 - 2s - loss: 0.0592 - acc: 0.9615 - val_loss: 0.3783 - val_acc: 0.8571 - 2s/epoch - 2s/step\n",
            "Epoch 4/10\n",
            "1/1 - 1s - loss: 0.0311 - acc: 1.0000 - val_loss: 0.5836 - val_acc: 0.8571 - 1s/epoch - 1s/step\n",
            "Epoch 5/10\n",
            "1/1 - 1s - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6565 - val_acc: 0.8571 - 1s/epoch - 1s/step\n",
            "Epoch 6/10\n",
            "1/1 - 1s - loss: 0.0201 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 0.8571 - 1s/epoch - 1s/step\n",
            "Epoch 7/10\n",
            "1/1 - 2s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6469 - val_acc: 0.8571 - 2s/epoch - 2s/step\n",
            "Epoch 8/10\n",
            "1/1 - 2s - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5065 - val_acc: 0.8571 - 2s/epoch - 2s/step\n",
            "Epoch 9/10\n",
            "1/1 - 1s - loss: 2.5738e-04 - acc: 1.0000 - val_loss: 0.3961 - val_acc: 0.8571 - 1s/epoch - 1s/step\n",
            "Epoch 10/10\n",
            "1/1 - 1s - loss: 7.4841e-04 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.8571 - 1s/epoch - 1s/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    # steps_per_epoch=150 // bs,\n",
        "                    epochs=10,\n",
        "                    # validation_steps=50 // bs,\n",
        "                    verbose=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "c621e5a433137a73884b017f14c16a9e14b23ff65621e82f0e85b98740ce3bcb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
