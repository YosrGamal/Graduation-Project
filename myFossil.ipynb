{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M5Ju4fFQQdDP"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Projects\\Graduation\\Graduation-Project\\myFossil.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/Graduation/Graduation-Project/myFossil.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Import the necessary packages\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/Graduation/Graduation-Project/myFossil.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/Graduation/Graduation-Project/myFossil.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpatches\u001b[39;00m \u001b[39mimport\u001b[39;00m cv2_imshow\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/Graduation/Graduation-Project/myFossil.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataGenerator\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Import the necessary packages\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
        "from sklearn.svm import SVR \n",
        "from imutils import paths\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import skimage.io\n",
        "import skimage.color\n",
        "import skimage.filters\n",
        "import tensorflow as tf\n",
        "import argparse\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mounting and defining global variable path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive')\n",
        "image_path = \"/content/gdrive/My Drive/flash_off_elepahntOneToEight\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel 'anaconda3 (Python 3.9.12)' due to connection timeout. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "path=image_path\n",
        "img = cv2.imread(path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing 3 thresholds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read the image\n",
        "img = cv2.imread(\"/content/gdrive/My Drive/IMG_0014.jpg\")\n",
        "x=int(img.shape[0]/5)\n",
        "y=int(img.shape[1]/5)\n",
        "img = cv2.resize(img, (x, y), interpolation=cv2.INTER_NEAREST)\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "# apply simple thresholding with a hardcoded threshold value\n",
        "(T, threshInv) = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY_INV)\n",
        "\n",
        "print('simple thresholding ')\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "ax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "ax[1].imshow(cv2.cvtColor(threshInv, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "# binarize the image\n",
        "binr = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
        " \n",
        "print('binarized automatic thresholding')\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "ax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "ax[1].imshow(cv2.cvtColor(binr, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "mask = cv2.adaptiveThreshold(gray, \n",
        "                              255, \n",
        "                              cv2.ADAPTIVE_THRESH_MEAN_C, \n",
        "                              cv2.THRESH_BINARY, \n",
        "                              10001, \n",
        "                              70\n",
        ")\n",
        "\n",
        "print('adaptiveThreshold')\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "ax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "ax[1].imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjFYyiwTJTt"
      },
      "source": [
        "# **Moment invariant**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCK2tsTowP4n"
      },
      "source": [
        "Reading image file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = cv2.imread(\"Segmented_Teeth/segmented tooth1_1.png\")\n",
        "img2 = cv2.imread(\"Segmented_Teeth/segmented tooth1_2.png\")\n",
        "img3 = cv2.imread(\"Segmented_Teeth/segmented_tooth1_3.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL MOMENTS for img 1: [9.31673872e-04 3.94367501e-07 1.16589393e-10 1.50416801e-11\n",
            " 6.29560476e-22 9.44115823e-15 2.07860839e-23]\n",
            "ORIGINAL MOMENTS for img 2: [9.32487012e-04 4.19574583e-07 7.85269033e-11 1.14095140e-11\n",
            " 3.37913841e-22 7.05015323e-15 4.94653700e-23]\n",
            "ORIGINAL MOMENTS for img 3: [1.18052474e-03 9.45728897e-07 1.96083982e-10 8.24694512e-11\n",
            " 1.04041240e-20 7.77455385e-14 1.31763320e-21]\n"
          ]
        }
      ],
      "source": [
        "moments1 = cv2.HuMoments(cv2.moments(img1)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 1: {}\".format(moments1))\n",
        "\n",
        "moments2 = cv2.HuMoments(cv2.moments(img2)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 2: {}\".format(moments2))\n",
        "\n",
        "moments3 = cv2.HuMoments(cv2.moments(img3)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 3: {}\".format(moments3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log transformation for moments1 [ 3.03073608  6.40409888  9.93334096 10.82270365 21.20096254 14.02497472\n",
            " 22.68222732]\n",
            "log transformation for moments2 [ 3.03035721  6.37719083 10.10498153 10.94273285 21.47119402 14.15180144\n",
            " 22.30569874]\n",
            "log transformation for moments3 [ 2.92792491  6.02423334  9.70755788 10.0837069  19.98279448 13.10932452\n",
            " 20.88020547]\n"
          ]
        }
      ],
      "source": [
        "# for i in range(0,7):\n",
        "#    moments1[i] = -np.sign(1.0, moments1[i])*np.math.log10(np.abs(moments1[i]))\n",
        "   \n",
        "#-1* copysign(1.0, huMoments[i]) * log10(abs(huMoments[i]))\n",
        "\n",
        "lmoment1 = np.abs(np.log10(moments1))\n",
        "print('log transformation for moments1',lmoment1)\n",
        "lmoment2 = np.abs(np.log10(moments2))\n",
        "print('log transformation for moments2', lmoment2)\n",
        "lmoment3 = np.abs(np.log10(moments3))\n",
        "print('log transformation for moments3', lmoment3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between moment1 and moment2 0.5248576217835638\n"
          ]
        }
      ],
      "source": [
        "dist = np.linalg.norm(lmoment1 - lmoment2)\n",
        "print('Distance between moment1 and moment2',dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between moment1 and moment3 2.5142779577407346\n"
          ]
        }
      ],
      "source": [
        "dist = np.linalg.norm(lmoment1 - lmoment3)\n",
        "print('Distance between moment1 and moment3',dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *Data Augmentation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import argparse\n",
        "from imutils import paths\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "datapath=\"training dataset/crocodiles\"\n",
        "out=\"training dataset/crocodiles_aug\"\n",
        "\n",
        "datapath1=\"training dataset/sharks\"\n",
        "out1=\"training dataset/sharks_aug\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(datapath))\n",
        "imagePaths1 = list(paths.list_images(datapath1))\n",
        "data=[]\n",
        "data1=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training dataset/crocodiles\\17095-7.jpg\n",
            "training dataset/crocodiles\\alligator-crocodile-fossils-5.jpg\n",
            "training dataset/crocodiles\\alligator-crocodile-fossils-gator-tooth.jpg\n",
            "training dataset/crocodiles\\cretaceous-crocodile-tooth-from-morocco-sku-v1725-elosuchus-cherifiensis-p1785-4765_image.jpg\n",
            "training dataset/crocodiles\\crocodile-tooth-miocene-fossil_1_bc5be32c6b8c0b8c4e3650ffe3deadd4.jpg\n",
            "training dataset/crocodiles\\images (1).jpg\n",
            "training dataset/crocodiles\\images.jpg\n",
            "training dataset/crocodiles\\lf (1).jpg\n",
            "training dataset/crocodiles\\lf.jpg\n",
            "training dataset/crocodiles\\miocene-fossil-crocodile-tooth-from-bone-valley-phosphates-polk-county-florida-usa-sku-v3089-gavialosuchus-americanus-p6069-17444_zoom.jpg\n",
            "training dataset/crocodiles\\segmented tooth3_1.JPG\n",
            "training dataset/crocodiles\\segmented tooth3_2.JPG\n",
            "training dataset/crocodiles\\segmented tooth3_3.JPG\n",
            "training dataset/crocodiles\\segmented tooth3_4.JPG\n",
            "training dataset/crocodiles\\segmented_tooth2_1.JPG\n",
            "training dataset/crocodiles\\segmented_tooth2_2.JPG\n",
            "training dataset/crocodiles\\segmented_tooth2_3.JPG\n",
            "training dataset/crocodiles\\segmented_tooth2_4.JPG\n",
            "training dataset/crocodiles\\tooth 3.JPG\n",
            "training dataset/crocodiles\\tooth1.JPG\n",
            "training dataset/crocodiles\\tooth2.JPG\n",
            "training dataset/sharks\\-34.jpg\n",
            "training dataset/sharks\\16611-6.jpg\n",
            "training dataset/sharks\\202288-13.jpg\n",
            "training dataset/sharks\\214954-20.jpg\n",
            "training dataset/sharks\\222-Fossil-Shark-Teeth-Otodus-Khouribga-Morocco.jpeg\n",
            "training dataset/sharks\\272-2720875_shark-teeth-transparent-image-white-shark-teeth-png.png\n",
            "training dataset/sharks\\3-5-inch-miocene-megalodon-fossil-shark-tooth-from-south-carolina-usa-sku-v2938-otodus-carcharocles-megalodon-p5636-16112_zoom.jpg\n",
            "training dataset/sharks\\3-5-inch-miocene-megalodon-fossil-shark-tooth-from-south-carolina-usa-sku-v2939-otodus-carcharocles-megalodon-p5637-16114_image.jpg\n",
            "training dataset/sharks\\362828.jpg\n",
            "training dataset/sharks\\3d798ba4a20af2f297fc34cd3b3193d7--shark-tooth-extinct.jpg\n",
            "training dataset/sharks\\4-inch-miocene-megalodon-fossil-shark-tooth-from-south-carolina-usa-sku-v2859-otodus-carcharocles-megalodon-p5343-15084_image.jpg\n",
            "training dataset/sharks\\41-alvh8GXL._AC_SY1000_.jpg\n",
            "training dataset/sharks\\5cafd95b41cb7.jpg\n",
            "training dataset/sharks\\5e5da3393f9e4.jpg\n",
            "training dataset/sharks\\694940094001_6028045564001_6028048254001-vs.jpg\n",
            "training dataset/sharks\\83714-13.jpg\n",
            "training dataset/sharks\\ancient-fossil-shark-tooth-cut-out-on-white-2J8N8BP.jpg\n",
            "training dataset/sharks\\c1a03b836bb345c7a7dd5bcbe00f9ef5.jpeg\n",
            "training dataset/sharks\\ca01-1e.jpg\n",
            "training dataset/sharks\\cc7b0c2252dc1c775d4db4c059e3c838.jpg\n",
            "training dataset/sharks\\D_NQ_NP_871910-MLB50208229067_062022-O.jpg\n",
            "training dataset/sharks\\F002-F.jpg\n",
            "training dataset/sharks\\fossilised-shark-tooth-small_1.jpg\n",
            "training dataset/sharks\\Fossilized-Shark-Tooth-by-A2Z-Science-scaled.jpg\n",
            "training dataset/sharks\\Fossilized-Shark-Tooth-by-A2Z-Science.jpg\n",
            "training dataset/sharks\\fssth1007-hastalis-3.jpg\n",
            "training dataset/sharks\\GettyImages-508610924-5bb259c9cff47e002656a32e.jpg\n",
            "training dataset/sharks\\huge-5-inch-megalodon-shark-tooth-from-west-java-indonesia-sku-v1844-otodus-carcharocles-megalodon-p2310-6310_zoom.jpg\n",
            "training dataset/sharks\\images.jpg\n",
            "training dataset/sharks\\istockphoto-475196431-1024x1024.jpg\n",
            "training dataset/sharks\\JTMEG4-8.jpg\n",
            "training dataset/sharks\\kalifano-fossils-minerals-authentic-fossil-shark-tooth-from-morocco-st59-22585328271554.jpg.crdownload.jpg\n",
            "training dataset/sharks\\LC301-350.jpg\n",
            "training dataset/sharks\\NC056-F.jpg\n",
            "training dataset/sharks\\p003-1e.jpg\n",
            "training dataset/sharks\\P045-F.jpg\n",
            "training dataset/sharks\\s-l500 (1).jpg\n",
            "training dataset/sharks\\s-l500.jpg\n"
          ]
        }
      ],
      "source": [
        "for imagePath in imagePaths:\n",
        "    print(imagePath)\n",
        "    image = cv2.imread(imagePath)\n",
        "\t#cv2.imshow(image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    data.append(image)\n",
        "datanp=np.array(data)\n",
        "\n",
        "for imagePath1 in imagePaths1:\n",
        "    print(imagePath1)\n",
        "    image1 = cv2.imread(imagePath1)\n",
        "\t#cv2.imshow(image)\n",
        "    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "    image1 = cv2.resize(image1, (224, 224))\n",
        "    image1 = img_to_array(image1)\n",
        "    image1 = np.expand_dims(image1, axis=0)\n",
        "    data1.append(image1)\n",
        "datanp1=np.array(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "aug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "total = 0\n",
        "imageGen=[]\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "total = 0\n",
        "imageGen1=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] generating images...\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] generating images...\")\n",
        "\n",
        "# augmentedImages=[]\n",
        "for i in range(len(datanp)):\n",
        "        print(\"Generating is running\")\n",
        "  \n",
        "        imageGen= aug.flow(datanp[i], batch_size=1, save_to_dir=out,\n",
        "        save_prefix=\"image\", save_format=\"jpg\")\n",
        "        for image in imageGen:\n",
        "\t# increment our counter\n",
        "\t        total += 1\n",
        "\t# if we have reached the specified number of examples, break\n",
        "\t# from the loop\n",
        "\t        if (total%6==0):\n",
        "\t\t\t\t#total = 0\n",
        "\t\t        break\n",
        "\n",
        "# augmentedImages=[]\n",
        "for i in range(len(datanp1)):\n",
        "        print(\"Generating is running\")\n",
        "  \n",
        "        imageGen1= aug.flow(datanp1[i], batch_size=1, save_to_dir=out1,\n",
        "        save_prefix=\"image\", save_format=\"jpg\")\n",
        "        for image1 in imageGen1:\n",
        "\t# increment our counter\n",
        "\t        total += 1\n",
        "\t# if we have reached the specified number of examples, break\n",
        "\t# from the loop\n",
        "\t        if (total%6==0):\n",
        "\t\t\t\t#total = 0\n",
        "\t\t        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *CNN classification*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (180,180,3)) ,\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
        "    tf.keras.layers.Dropout(0.1,seed = 2019),\n",
        "    tf.keras.layers.Dense(400,activation =\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.3,seed = 2019),\n",
        "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.4,seed = 2019),\n",
        "    tf.keras.layers.Dense(200,activation =\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2,seed = 2019),\n",
        "    tf.keras.layers.Dense(2,activation = \"softmax\")   #Adding the Output Layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
        "adam=Adam(learning_rate=0.001)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 347 images belonging to 2 classes.\n",
            "Found 14 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "bs=30         #Setting batch size\n",
        "train_dir = \"training dataset\"   #Setting training directory\n",
        "validation_dir = \"validation dataset\"   #Setting testing directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "# All images will be rescaled by 1./255.\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(180,180))\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=bs,\n",
        "                                                         class_mode  = 'categorical',\n",
        "                                                         target_size=(180,180))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12/12 - 9s - loss: 0.6528 - acc: 0.6110 - val_loss: 0.6454 - val_acc: 0.5000 - 9s/epoch - 776ms/step\n",
            "Epoch 2/10\n",
            "12/12 - 5s - loss: 0.5426 - acc: 0.6830 - val_loss: 0.5943 - val_acc: 0.7857 - 5s/epoch - 440ms/step\n",
            "Epoch 3/10\n",
            "12/12 - 5s - loss: 0.4913 - acc: 0.8098 - val_loss: 0.4913 - val_acc: 0.7857 - 5s/epoch - 421ms/step\n",
            "Epoch 4/10\n",
            "12/12 - 5s - loss: 0.3131 - acc: 0.8761 - val_loss: 0.3467 - val_acc: 0.7857 - 5s/epoch - 412ms/step\n",
            "Epoch 5/10\n",
            "12/12 - 5s - loss: 0.4419 - acc: 0.7695 - val_loss: 0.3864 - val_acc: 0.8571 - 5s/epoch - 431ms/step\n",
            "Epoch 6/10\n",
            "12/12 - 5s - loss: 0.3790 - acc: 0.8012 - val_loss: 0.3480 - val_acc: 0.7857 - 5s/epoch - 421ms/step\n",
            "Epoch 7/10\n",
            "12/12 - 5s - loss: 0.2715 - acc: 0.9020 - val_loss: 0.5556 - val_acc: 0.7857 - 5s/epoch - 413ms/step\n",
            "Epoch 8/10\n",
            "12/12 - 5s - loss: 0.2287 - acc: 0.9193 - val_loss: 0.4303 - val_acc: 0.7143 - 5s/epoch - 440ms/step\n",
            "Epoch 9/10\n",
            "12/12 - 5s - loss: 0.1981 - acc: 0.9107 - val_loss: 0.3760 - val_acc: 0.7857 - 5s/epoch - 438ms/step\n",
            "Epoch 10/10\n",
            "12/12 - 5s - loss: 0.1673 - acc: 0.9308 - val_loss: 0.2296 - val_acc: 0.8571 - 5s/epoch - 444ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    # steps_per_epoch=150 // bs,\n",
        "                    epochs=10,\n",
        "                    # validation_steps=50 // bs,\n",
        "                    verbose=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "01b88e8448c57eed80be5eacadf55a4951e49f78a398548edc15369e5e7cb9b8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
