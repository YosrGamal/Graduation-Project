{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "M5Ju4fFQQdDP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from imutils import paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CjFYyiwTJTt"
      },
      "source": [
        "# **Moment invariant**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCK2tsTowP4n"
      },
      "source": [
        "Reading image file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = cv2.imread(\"Segmented_Teeth/segmented tooth1_1.png\")\n",
        "img2 = cv2.imread(\"Segmented_Teeth/segmented tooth1_2.png\")\n",
        "img3 = cv2.imread(\"Segmented_Teeth/segmented_tooth1_3.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ORIGINAL MOMENTS for img 1: [9.31673872e-04 3.94367501e-07 1.16589393e-10 1.50416801e-11\n",
            " 6.29560476e-22 9.44115823e-15 2.07860839e-23]\n",
            "ORIGINAL MOMENTS for img 2: [9.32487012e-04 4.19574583e-07 7.85269033e-11 1.14095140e-11\n",
            " 3.37913841e-22 7.05015323e-15 4.94653700e-23]\n",
            "ORIGINAL MOMENTS for img 3: [1.18052474e-03 9.45728897e-07 1.96083982e-10 8.24694512e-11\n",
            " 1.04041240e-20 7.77455385e-14 1.31763320e-21]\n"
          ]
        }
      ],
      "source": [
        "moments1 = cv2.HuMoments(cv2.moments(img1)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 1: {}\".format(moments1))\n",
        "\n",
        "moments2 = cv2.HuMoments(cv2.moments(img2)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 2: {}\".format(moments2))\n",
        "\n",
        "moments3 = cv2.HuMoments(cv2.moments(img3)).flatten()\n",
        "print(\"ORIGINAL MOMENTS for img 3: {}\".format(moments3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "log transformation for moments1 [ 3.03073608  6.40409888  9.93334096 10.82270365 21.20096254 14.02497472\n",
            " 22.68222732]\n",
            "log transformation for moments2 [ 3.03035721  6.37719083 10.10498153 10.94273285 21.47119402 14.15180144\n",
            " 22.30569874]\n",
            "log transformation for moments3 [ 2.92792491  6.02423334  9.70755788 10.0837069  19.98279448 13.10932452\n",
            " 20.88020547]\n"
          ]
        }
      ],
      "source": [
        "# for i in range(0,7):\n",
        "#    moments1[i] = -np.sign(1.0, moments1[i])*np.math.log10(np.abs(moments1[i]))\n",
        "   \n",
        "#-1* copysign(1.0, huMoments[i]) * log10(abs(huMoments[i]))\n",
        "\n",
        "lmoment1 = np.abs(np.log10(moments1))\n",
        "print('log transformation for moments1',lmoment1)\n",
        "lmoment2 = np.abs(np.log10(moments2))\n",
        "print('log transformation for moments2', lmoment2)\n",
        "lmoment3 = np.abs(np.log10(moments3))\n",
        "print('log transformation for moments3', lmoment3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between moment1 and moment2 0.5248576217835638\n"
          ]
        }
      ],
      "source": [
        "dist = np.linalg.norm(lmoment1 - lmoment2)\n",
        "print('Distance between moment1 and moment2',dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance between moment1 and moment3 2.5142779577407346\n"
          ]
        }
      ],
      "source": [
        "dist = np.linalg.norm(lmoment1 - lmoment3)\n",
        "print('Distance between moment1 and moment3',dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *Data Augmentation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras_preprocessing.image import img_to_array\n",
        "from keras_preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import argparse\n",
        "from imutils import paths\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "datapath=\"training dataset/crocodiles\"\n",
        "out=\"training dataset/crocodiles_aug\"\n",
        "\n",
        "datapath1=\"training dataset/sharks\"\n",
        "out1=\"training dataset/sharks_aug\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(datapath))\n",
        "imagePaths1 = list(paths.list_images(datapath1))\n",
        "data=[]\n",
        "data1=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training dataset/crocodiles_aug\\alligator-crocodile-fossils-5.jpg\n",
            "training dataset/crocodiles_aug\\cretaceous-crocodile-tooth-from-morocco-sku-v1725-elosuchus-cherifiensis-p1785-4765_image.jpg\n",
            "training dataset/crocodiles_aug\\images (1).jpg\n",
            "training dataset/crocodiles_aug\\image_0_1016.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1025.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1066.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1092.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1136.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1162.jpg\n",
            "training dataset/crocodiles_aug\\image_0_129.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1300.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1316.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1337.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1380.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1443.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1504.jpg\n",
            "training dataset/crocodiles_aug\\image_0_152.jpg\n",
            "training dataset/crocodiles_aug\\image_0_174.jpg\n",
            "training dataset/crocodiles_aug\\image_0_1832.jpg\n",
            "training dataset/crocodiles_aug\\image_0_200.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2009.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2152.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2154.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2162.jpg\n",
            "training dataset/crocodiles_aug\\image_0_243.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2478.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2556.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2559.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2639.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2662.jpg\n",
            "training dataset/crocodiles_aug\\image_0_268.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2817.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2836.jpg\n",
            "training dataset/crocodiles_aug\\image_0_2901.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3058.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3164.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3222.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3248.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3328.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3391.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3488.jpg\n",
            "training dataset/crocodiles_aug\\image_0_349.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3513.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3524.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3583.jpg\n",
            "training dataset/crocodiles_aug\\image_0_36.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3712.jpg\n",
            "training dataset/crocodiles_aug\\image_0_3998.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4009.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4042.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4117.jpg\n",
            "training dataset/crocodiles_aug\\image_0_429.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4300.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4521.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4689.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4726.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4730.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4733.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4834.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4855.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4867.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4964.jpg\n",
            "training dataset/crocodiles_aug\\image_0_4976.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5012.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5039.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5081.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5174.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5187.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5240.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5353.jpg\n",
            "training dataset/crocodiles_aug\\image_0_560.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5794.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5826.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5890.jpg\n",
            "training dataset/crocodiles_aug\\image_0_5980.jpg\n",
            "training dataset/crocodiles_aug\\image_0_60.jpg\n",
            "training dataset/crocodiles_aug\\image_0_6000.jpg\n",
            "training dataset/crocodiles_aug\\image_0_6078.jpg\n",
            "training dataset/crocodiles_aug\\image_0_6170.jpg\n",
            "training dataset/crocodiles_aug\\image_0_619.jpg\n",
            "training dataset/crocodiles_aug\\image_0_630.jpg\n",
            "training dataset/crocodiles_aug\\image_0_6780.jpg\n",
            "training dataset/crocodiles_aug\\image_0_6853.jpg\n",
            "training dataset/crocodiles_aug\\image_0_6892.jpg\n",
            "training dataset/crocodiles_aug\\image_0_6998.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7045.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7129.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7207.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7452.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7457.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7487.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7521.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7648.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7651.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7732.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7812.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7888.jpg\n",
            "training dataset/crocodiles_aug\\image_0_7935.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8113.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8181.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8217.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8317.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8329.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8392.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8506.jpg\n",
            "training dataset/crocodiles_aug\\image_0_854.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8544.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8555.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8602.jpg\n",
            "training dataset/crocodiles_aug\\image_0_875.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8889.jpg\n",
            "training dataset/crocodiles_aug\\image_0_8977.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9035.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9046.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9082.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9132.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9152.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9169.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9405.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9416.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9527.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9635.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9639.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9805.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9877.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9884.jpg\n",
            "training dataset/crocodiles_aug\\image_0_9890.jpg\n",
            "training dataset/crocodiles_aug\\lf (1).jpg\n",
            "training dataset/crocodiles_aug\\segmented tooth3_1.JPG\n",
            "training dataset/crocodiles_aug\\segmented_tooth2_1.JPG\n",
            "training dataset/crocodiles_aug\\tooth1.JPG\n",
            "training dataset/sharks_aug\\202288-13.jpg\n",
            "training dataset/sharks_aug\\3-5-inch-miocene-megalodon-fossil-shark-tooth-from-south-carolina-usa-sku-v2938-otodus-carcharocles-megalodon-p5636-16112_zoom.jpg\n",
            "training dataset/sharks_aug\\4-inch-miocene-megalodon-fossil-shark-tooth-from-south-carolina-usa-sku-v2859-otodus-carcharocles-megalodon-p5343-15084_image.jpg\n",
            "training dataset/sharks_aug\\cc7b0c2252dc1c775d4db4c059e3c838.jpg\n",
            "training dataset/sharks_aug\\Fossilized-Shark-Tooth-by-A2Z-Science-scaled.jpg\n",
            "training dataset/sharks_aug\\image_0_1017.jpg\n",
            "training dataset/sharks_aug\\image_0_1107.jpg\n",
            "training dataset/sharks_aug\\image_0_1128.jpg\n",
            "training dataset/sharks_aug\\image_0_1260.jpg\n",
            "training dataset/sharks_aug\\image_0_1297.jpg\n",
            "training dataset/sharks_aug\\image_0_1331.jpg\n",
            "training dataset/sharks_aug\\image_0_1341.jpg\n",
            "training dataset/sharks_aug\\image_0_1376.jpg\n",
            "training dataset/sharks_aug\\image_0_1439.jpg\n",
            "training dataset/sharks_aug\\image_0_1470.jpg\n",
            "training dataset/sharks_aug\\image_0_1507.jpg\n",
            "training dataset/sharks_aug\\image_0_1514.jpg\n",
            "training dataset/sharks_aug\\image_0_1554.jpg\n",
            "training dataset/sharks_aug\\image_0_1563.jpg\n",
            "training dataset/sharks_aug\\image_0_157.jpg\n",
            "training dataset/sharks_aug\\image_0_1570.jpg\n",
            "training dataset/sharks_aug\\image_0_1574.jpg\n",
            "training dataset/sharks_aug\\image_0_1584.jpg\n",
            "training dataset/sharks_aug\\image_0_1610.jpg\n",
            "training dataset/sharks_aug\\image_0_1632.jpg\n",
            "training dataset/sharks_aug\\image_0_167.jpg\n",
            "training dataset/sharks_aug\\image_0_17.jpg\n",
            "training dataset/sharks_aug\\image_0_1713.jpg\n",
            "training dataset/sharks_aug\\image_0_1782.jpg\n",
            "training dataset/sharks_aug\\image_0_1795.jpg\n",
            "training dataset/sharks_aug\\image_0_1836.jpg\n",
            "training dataset/sharks_aug\\image_0_1863.jpg\n",
            "training dataset/sharks_aug\\image_0_1951.jpg\n",
            "training dataset/sharks_aug\\image_0_2026.jpg\n",
            "training dataset/sharks_aug\\image_0_2095.jpg\n",
            "training dataset/sharks_aug\\image_0_2111.jpg\n",
            "training dataset/sharks_aug\\image_0_2127.jpg\n",
            "training dataset/sharks_aug\\image_0_2180.jpg\n",
            "training dataset/sharks_aug\\image_0_2186.jpg\n",
            "training dataset/sharks_aug\\image_0_2329.jpg\n",
            "training dataset/sharks_aug\\image_0_2330.jpg\n",
            "training dataset/sharks_aug\\image_0_2393.jpg\n",
            "training dataset/sharks_aug\\image_0_2434.jpg\n",
            "training dataset/sharks_aug\\image_0_2501.jpg\n",
            "training dataset/sharks_aug\\image_0_2553.jpg\n",
            "training dataset/sharks_aug\\image_0_2605.jpg\n",
            "training dataset/sharks_aug\\image_0_2620.jpg\n",
            "training dataset/sharks_aug\\image_0_2630.jpg\n",
            "training dataset/sharks_aug\\image_0_2642.jpg\n",
            "training dataset/sharks_aug\\image_0_2648.jpg\n",
            "training dataset/sharks_aug\\image_0_2653.jpg\n",
            "training dataset/sharks_aug\\image_0_2660.jpg\n",
            "training dataset/sharks_aug\\image_0_2669.jpg\n",
            "training dataset/sharks_aug\\image_0_2722.jpg\n",
            "training dataset/sharks_aug\\image_0_2747.jpg\n",
            "training dataset/sharks_aug\\image_0_2766.jpg\n",
            "training dataset/sharks_aug\\image_0_2778.jpg\n",
            "training dataset/sharks_aug\\image_0_2926.jpg\n",
            "training dataset/sharks_aug\\image_0_2927.jpg\n",
            "training dataset/sharks_aug\\image_0_2932.jpg\n",
            "training dataset/sharks_aug\\image_0_295.jpg\n",
            "training dataset/sharks_aug\\image_0_3047.jpg\n",
            "training dataset/sharks_aug\\image_0_306.jpg\n",
            "training dataset/sharks_aug\\image_0_3076.jpg\n",
            "training dataset/sharks_aug\\image_0_3102.jpg\n",
            "training dataset/sharks_aug\\image_0_3164.jpg\n",
            "training dataset/sharks_aug\\image_0_3175.jpg\n",
            "training dataset/sharks_aug\\image_0_3267.jpg\n",
            "training dataset/sharks_aug\\image_0_3268.jpg\n",
            "training dataset/sharks_aug\\image_0_3287.jpg\n",
            "training dataset/sharks_aug\\image_0_3307.jpg\n",
            "training dataset/sharks_aug\\image_0_3357.jpg\n",
            "training dataset/sharks_aug\\image_0_3426.jpg\n",
            "training dataset/sharks_aug\\image_0_3482.jpg\n",
            "training dataset/sharks_aug\\image_0_3496.jpg\n",
            "training dataset/sharks_aug\\image_0_3574.jpg\n",
            "training dataset/sharks_aug\\image_0_359.jpg\n",
            "training dataset/sharks_aug\\image_0_3644.jpg\n",
            "training dataset/sharks_aug\\image_0_3645.jpg\n",
            "training dataset/sharks_aug\\image_0_3665.jpg\n",
            "training dataset/sharks_aug\\image_0_3671.jpg\n",
            "training dataset/sharks_aug\\image_0_385.jpg\n",
            "training dataset/sharks_aug\\image_0_3863.jpg\n",
            "training dataset/sharks_aug\\image_0_3864.jpg\n",
            "training dataset/sharks_aug\\image_0_3878.jpg\n",
            "training dataset/sharks_aug\\image_0_3922.jpg\n",
            "training dataset/sharks_aug\\image_0_3947.jpg\n",
            "training dataset/sharks_aug\\image_0_4004.jpg\n",
            "training dataset/sharks_aug\\image_0_4122.jpg\n",
            "training dataset/sharks_aug\\image_0_432.jpg\n",
            "training dataset/sharks_aug\\image_0_4367.jpg\n",
            "training dataset/sharks_aug\\image_0_4519.jpg\n",
            "training dataset/sharks_aug\\image_0_4591.jpg\n",
            "training dataset/sharks_aug\\image_0_4594.jpg\n",
            "training dataset/sharks_aug\\image_0_4631.jpg\n",
            "training dataset/sharks_aug\\image_0_4673.jpg\n",
            "training dataset/sharks_aug\\image_0_4686.jpg\n",
            "training dataset/sharks_aug\\image_0_4701.jpg\n",
            "training dataset/sharks_aug\\image_0_4718.jpg\n",
            "training dataset/sharks_aug\\image_0_4854.jpg\n",
            "training dataset/sharks_aug\\image_0_4882.jpg\n",
            "training dataset/sharks_aug\\image_0_4945.jpg\n",
            "training dataset/sharks_aug\\image_0_516.jpg\n",
            "training dataset/sharks_aug\\image_0_5166.jpg\n",
            "training dataset/sharks_aug\\image_0_5169.jpg\n",
            "training dataset/sharks_aug\\image_0_5245.jpg\n",
            "training dataset/sharks_aug\\image_0_5262.jpg\n",
            "training dataset/sharks_aug\\image_0_5317.jpg\n",
            "training dataset/sharks_aug\\image_0_5323.jpg\n",
            "training dataset/sharks_aug\\image_0_5337.jpg\n",
            "training dataset/sharks_aug\\image_0_5373.jpg\n",
            "training dataset/sharks_aug\\image_0_5375.jpg\n",
            "training dataset/sharks_aug\\image_0_5379.jpg\n",
            "training dataset/sharks_aug\\image_0_5382.jpg\n",
            "training dataset/sharks_aug\\image_0_540.jpg\n",
            "training dataset/sharks_aug\\image_0_5405.jpg\n",
            "training dataset/sharks_aug\\image_0_5420.jpg\n",
            "training dataset/sharks_aug\\image_0_5444.jpg\n",
            "training dataset/sharks_aug\\image_0_5446.jpg\n",
            "training dataset/sharks_aug\\image_0_5493.jpg\n",
            "training dataset/sharks_aug\\image_0_5495.jpg\n",
            "training dataset/sharks_aug\\image_0_5497.jpg\n",
            "training dataset/sharks_aug\\image_0_5519.jpg\n",
            "training dataset/sharks_aug\\image_0_5563.jpg\n",
            "training dataset/sharks_aug\\image_0_5628.jpg\n",
            "training dataset/sharks_aug\\image_0_58.jpg\n",
            "training dataset/sharks_aug\\image_0_5857.jpg\n",
            "training dataset/sharks_aug\\image_0_5887.jpg\n",
            "training dataset/sharks_aug\\image_0_5952.jpg\n",
            "training dataset/sharks_aug\\image_0_6008.jpg\n",
            "training dataset/sharks_aug\\image_0_6013.jpg\n",
            "training dataset/sharks_aug\\image_0_6070.jpg\n",
            "training dataset/sharks_aug\\image_0_6195.jpg\n",
            "training dataset/sharks_aug\\image_0_6237.jpg\n",
            "training dataset/sharks_aug\\image_0_6244.jpg\n",
            "training dataset/sharks_aug\\image_0_6311.jpg\n",
            "training dataset/sharks_aug\\image_0_6336.jpg\n",
            "training dataset/sharks_aug\\image_0_6434.jpg\n",
            "training dataset/sharks_aug\\image_0_6454.jpg\n",
            "training dataset/sharks_aug\\image_0_6466.jpg\n",
            "training dataset/sharks_aug\\image_0_6473.jpg\n",
            "training dataset/sharks_aug\\image_0_653.jpg\n",
            "training dataset/sharks_aug\\image_0_6530.jpg\n",
            "training dataset/sharks_aug\\image_0_6531.jpg\n",
            "training dataset/sharks_aug\\image_0_6568.jpg\n",
            "training dataset/sharks_aug\\image_0_6577.jpg\n",
            "training dataset/sharks_aug\\image_0_6604.jpg\n",
            "training dataset/sharks_aug\\image_0_6614.jpg\n",
            "training dataset/sharks_aug\\image_0_663.jpg\n",
            "training dataset/sharks_aug\\image_0_6678.jpg\n",
            "training dataset/sharks_aug\\image_0_6680.jpg\n",
            "training dataset/sharks_aug\\image_0_6694.jpg\n",
            "training dataset/sharks_aug\\image_0_6715.jpg\n",
            "training dataset/sharks_aug\\image_0_6771.jpg\n",
            "training dataset/sharks_aug\\image_0_6894.jpg\n",
            "training dataset/sharks_aug\\image_0_6934.jpg\n",
            "training dataset/sharks_aug\\image_0_6953.jpg\n",
            "training dataset/sharks_aug\\image_0_7073.jpg\n",
            "training dataset/sharks_aug\\image_0_7242.jpg\n",
            "training dataset/sharks_aug\\image_0_7253.jpg\n",
            "training dataset/sharks_aug\\image_0_7282.jpg\n",
            "training dataset/sharks_aug\\image_0_7286.jpg\n",
            "training dataset/sharks_aug\\image_0_7316.jpg\n",
            "training dataset/sharks_aug\\image_0_7348.jpg\n",
            "training dataset/sharks_aug\\image_0_7422.jpg\n",
            "training dataset/sharks_aug\\image_0_7452.jpg\n",
            "training dataset/sharks_aug\\image_0_7503.jpg\n",
            "training dataset/sharks_aug\\image_0_7536.jpg\n",
            "training dataset/sharks_aug\\image_0_7813.jpg\n",
            "training dataset/sharks_aug\\image_0_7817.jpg\n",
            "training dataset/sharks_aug\\image_0_7826.jpg\n",
            "training dataset/sharks_aug\\image_0_7860.jpg\n",
            "training dataset/sharks_aug\\image_0_7931.jpg\n",
            "training dataset/sharks_aug\\image_0_7982.jpg\n",
            "training dataset/sharks_aug\\image_0_800.jpg\n",
            "training dataset/sharks_aug\\image_0_8034.jpg\n",
            "training dataset/sharks_aug\\image_0_8043.jpg\n",
            "training dataset/sharks_aug\\image_0_813.jpg\n",
            "training dataset/sharks_aug\\image_0_8217.jpg\n",
            "training dataset/sharks_aug\\image_0_8320.jpg\n",
            "training dataset/sharks_aug\\image_0_839.jpg\n",
            "training dataset/sharks_aug\\image_0_8441.jpg\n",
            "training dataset/sharks_aug\\image_0_8473.jpg\n",
            "training dataset/sharks_aug\\image_0_8633.jpg\n",
            "training dataset/sharks_aug\\image_0_8710.jpg\n",
            "training dataset/sharks_aug\\image_0_8779.jpg\n",
            "training dataset/sharks_aug\\image_0_8781.jpg\n",
            "training dataset/sharks_aug\\image_0_8833.jpg\n",
            "training dataset/sharks_aug\\image_0_8837.jpg\n",
            "training dataset/sharks_aug\\image_0_8845.jpg\n",
            "training dataset/sharks_aug\\image_0_8856.jpg\n",
            "training dataset/sharks_aug\\image_0_8978.jpg\n",
            "training dataset/sharks_aug\\image_0_9076.jpg\n",
            "training dataset/sharks_aug\\image_0_9105.jpg\n",
            "training dataset/sharks_aug\\image_0_9106.jpg\n",
            "training dataset/sharks_aug\\image_0_911.jpg\n",
            "training dataset/sharks_aug\\image_0_9117.jpg\n",
            "training dataset/sharks_aug\\image_0_9171.jpg\n",
            "training dataset/sharks_aug\\image_0_9180.jpg\n",
            "training dataset/sharks_aug\\image_0_9206.jpg\n",
            "training dataset/sharks_aug\\image_0_9240.jpg\n",
            "training dataset/sharks_aug\\image_0_9291.jpg\n",
            "training dataset/sharks_aug\\image_0_9335.jpg\n",
            "training dataset/sharks_aug\\image_0_9426.jpg\n",
            "training dataset/sharks_aug\\image_0_9444.jpg\n",
            "training dataset/sharks_aug\\image_0_9460.jpg\n",
            "training dataset/sharks_aug\\image_0_9468.jpg\n",
            "training dataset/sharks_aug\\image_0_9481.jpg\n",
            "training dataset/sharks_aug\\image_0_9506.jpg\n",
            "training dataset/sharks_aug\\image_0_9529.jpg\n",
            "training dataset/sharks_aug\\image_0_9533.jpg\n",
            "training dataset/sharks_aug\\image_0_9534.jpg\n",
            "training dataset/sharks_aug\\image_0_9636.jpg\n",
            "training dataset/sharks_aug\\image_0_9653.jpg\n",
            "training dataset/sharks_aug\\image_0_9667.jpg\n",
            "training dataset/sharks_aug\\image_0_9683.jpg\n",
            "training dataset/sharks_aug\\image_0_9705.jpg\n",
            "training dataset/sharks_aug\\image_0_9708.jpg\n",
            "training dataset/sharks_aug\\image_0_9715.jpg\n",
            "training dataset/sharks_aug\\image_0_9747.jpg\n",
            "training dataset/sharks_aug\\image_0_9775.jpg\n",
            "training dataset/sharks_aug\\image_0_9776.jpg\n",
            "training dataset/sharks_aug\\image_0_9785.jpg\n",
            "training dataset/sharks_aug\\image_0_9822.jpg\n",
            "training dataset/sharks_aug\\image_0_9866.jpg\n",
            "training dataset/sharks_aug\\image_0_9880.jpg\n",
            "training dataset/sharks_aug\\image_0_9893.jpg\n",
            "training dataset/sharks_aug\\image_0_9998.jpg\n",
            "training dataset/sharks_aug\\JTMEG4-8.jpg\n",
            "training dataset/sharks_aug\\s-l500.jpg\n"
          ]
        }
      ],
      "source": [
        "for imagePath in imagePaths:\n",
        "    print(imagePath)\n",
        "    image = cv2.imread(imagePath)\n",
        "\t#cv2.imshow(image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    data.append(image)\n",
        "datanp=np.array(data)\n",
        "\n",
        "for imagePath1 in imagePaths1:\n",
        "    print(imagePath1)\n",
        "    image1 = cv2.imread(imagePath1)\n",
        "\t#cv2.imshow(image)\n",
        "    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "    image1 = cv2.resize(image1, (224, 224))\n",
        "    image1 = img_to_array(image1)\n",
        "    image1 = np.expand_dims(image1, axis=0)\n",
        "    data1.append(image1)\n",
        "datanp1=np.array(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "aug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "total = 0\n",
        "imageGen=[]\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "total = 0\n",
        "imageGen1=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] generating images...\n",
            "[INFO] generating images...\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n",
            "Generating is running\n"
          ]
        }
      ],
      "source": [
        "print(\"[INFO] generating images...\")\n",
        "\n",
        "# augmentedImages=[]\n",
        "for i in range(len(datanp)):\n",
        "        print(\"Generating is running\")\n",
        "  \n",
        "        imageGen= aug.flow(datanp[i], batch_size=1, save_to_dir=out,\n",
        "        save_prefix=\"image\", save_format=\"jpg\")\n",
        "        for image in imageGen:\n",
        "\t# increment our counter\n",
        "\t        total += 1\n",
        "\t# if we have reached the specified number of examples, break\n",
        "\t# from the loop\n",
        "\t     #   if (total%6==0):\n",
        "\t\t\t\t#total = 0\n",
        "\t\t       # break\n",
        "\n",
        "# augmentedImages=[]\n",
        "for i in range(len(datanp1)):\n",
        "        print(\"Generating is running\")\n",
        "  \n",
        "        imageGen1= aug.flow(datanp1[i], batch_size=1, save_to_dir=out1,\n",
        "        save_prefix=\"image\", save_format=\"jpg\")\n",
        "        for image1 in imageGen1:\n",
        "\t# increment our counter\n",
        "\t        total += 1\n",
        "\t# if we have reached the specified number of examples, break\n",
        "\t# from the loop\n",
        "\t##        if (total%6==0):\n",
        "\t\t\t\t#total = 0\n",
        "\t\t      #  break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **SVM classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir_path = r'/content/drive/Shareddrives/Graduation Project/Dataset/Teeth images'\n",
        "categories = ['Afradapis', 'Elephant', 'Hyrax' , 'Masrasector' , 'Sharks']\n",
        "IMG_SIZE=100\n",
        "for category in categories:\n",
        "  path = os.path.join(dir_path,category)\n",
        "  for img in os.listdir(path):\n",
        "      img_array=cv2.imread(os.path.join(path,img))\n",
        "      plt.imshow(img_array)\n",
        "      plt.show()\n",
        "      break\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_data=[]\n",
        "def create_training_data():\n",
        "    for category in categories:\n",
        "        path=os.path.join(dir_path, category)\n",
        "        class_num=categories.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array=cv2.imread(os.path.join(path,img))\n",
        "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
        "                training_data.append([new_array,class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "create_training_data()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(training_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lenofimage = len(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for categories, label in training_data:\n",
        "    X.append(categories)\n",
        "    y.append(label)\n",
        "X= np.array(X).reshape(lenofimage,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = X/255.0\n",
        "X[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y=np.array(y)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "svc = svm.SVC(kernel='rbf', C=1,gamma='auto').fit(X, y) #rbf model kernal not linear \n",
        "svc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y2 = svc.predict(X_test)\n",
        "print(\"Accuracy on unknown data is\",accuracy_score(y_test,y2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Accuracy on unknown data is\",classification_report(y_test,y2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *CNN classification*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (180,180,3)) ,\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
        "    tf.keras.layers.Dropout(0.1,seed = 2019),\n",
        "    tf.keras.layers.Dense(400,activation =\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.3,seed = 2019),\n",
        "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.4,seed = 2019),\n",
        "    tf.keras.layers.Dense(200,activation =\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2,seed = 2019),\n",
        "    tf.keras.layers.Dense(2,activation = \"softmax\")   #Adding the Output Layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m adam\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "adam=Adam(learning_rate=0.001)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 347 images belonging to 2 classes.\n",
            "Found 14 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "bs=30         #Setting batch size\n",
        "train_dir = \"training dataset\"   #Setting training directory\n",
        "validation_dir = \"validation dataset\"   #Setting testing directory\n",
        "from keras_preprocessing.image import ImageDataGenerator \n",
        "# All images will be rescaled by 1./255.\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\n",
        "train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(180,180))\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=bs,\n",
        "                                                         class_mode  = 'categorical',\n",
        "                                                         target_size=(180,180))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12/12 - 8s - loss: 0.6903 - acc: 0.5562 - val_loss: 0.7398 - val_acc: 0.5000 - 8s/epoch - 707ms/step\n",
            "Epoch 2/10\n",
            "12/12 - 7s - loss: 0.6173 - acc: 0.6427 - val_loss: 0.6470 - val_acc: 0.5000 - 7s/epoch - 570ms/step\n",
            "Epoch 3/10\n",
            "12/12 - 7s - loss: 0.5778 - acc: 0.6455 - val_loss: 0.6955 - val_acc: 0.5000 - 7s/epoch - 572ms/step\n",
            "Epoch 4/10\n",
            "12/12 - 8s - loss: 0.6035 - acc: 0.6138 - val_loss: 0.6859 - val_acc: 0.5000 - 8s/epoch - 633ms/step\n",
            "Epoch 5/10\n",
            "12/12 - 7s - loss: 0.5858 - acc: 0.6282 - val_loss: 0.6505 - val_acc: 0.5000 - 7s/epoch - 601ms/step\n",
            "Epoch 6/10\n",
            "12/12 - 7s - loss: 0.5530 - acc: 0.6427 - val_loss: 0.6138 - val_acc: 0.5000 - 7s/epoch - 599ms/step\n",
            "Epoch 7/10\n",
            "12/12 - 8s - loss: 0.5027 - acc: 0.6916 - val_loss: 0.5115 - val_acc: 0.7857 - 8s/epoch - 632ms/step\n",
            "Epoch 8/10\n",
            "12/12 - 7s - loss: 0.4818 - acc: 0.8213 - val_loss: 0.3063 - val_acc: 0.7857 - 7s/epoch - 584ms/step\n",
            "Epoch 9/10\n",
            "12/12 - 7s - loss: 0.4094 - acc: 0.7954 - val_loss: 0.4432 - val_acc: 0.7143 - 7s/epoch - 586ms/step\n",
            "Epoch 10/10\n",
            "12/12 - 8s - loss: 0.3272 - acc: 0.8357 - val_loss: 0.3896 - val_acc: 0.7857 - 8s/epoch - 657ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    # steps_per_epoch=150 // bs,\n",
        "                    epochs=10,\n",
        "                    # validation_steps=50 // bs,\n",
        "                    verbose=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "66eba28a75a64fbe1a9b9c30d27f7c856726c51cbbef86297708eae4ce175db0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
